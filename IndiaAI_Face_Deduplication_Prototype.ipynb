{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d30404",
   "metadata": {},
   "source": [
    "# IndiaAI Face Authentication Challenge\n",
    "## Privacy-Preserving De-duplication System\n",
    "\n",
    "This prototype demonstrates a scalable, privacy-first approach to face-based application de-duplication for large-scale government examinations.\n",
    "\n",
    "### Key Features\n",
    "- Two-stage de-duplication (LSH blocking + deep matching)\n",
    "- Privacy-by-design with cancelable biometric templates\n",
    "- Passive liveness detection for anti-spoofing\n",
    "- Fairness monitoring across demographics\n",
    "- Complete audit trail for transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e62f6",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "import hmac\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import warnings\n",
    "import urllib.request\n",
    "import tarfile\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning & Similarity Search\n",
    "import faiss\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Cryptography\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Visualization & Analysis\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import time\n",
    "\n",
    "print(\"✓ All dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Configuration\n",
    "class Config:\n",
    "    # Privacy & Security\n",
    "    TEMPLATE_KEY = get_random_bytes(32)\n",
    "    HASH_SECRET = get_random_bytes(16)\n",
    "    EMBEDDING_DIM = 512\n",
    "    CANCELABLE_DIM = 256\n",
    "    \n",
    "    # LSH Parameters\n",
    "    LSH_NUM_TABLES = 16\n",
    "    LSH_NUM_BITS = 12\n",
    "    MAX_CANDIDATES_PER_QUERY = 100\n",
    "    \n",
    "    # Matching Thresholds\n",
    "    MATCH_THRESHOLD_HIGH = 0.85\n",
    "    MATCH_THRESHOLD_LOW = 0.65\n",
    "    \n",
    "    # Quality & Liveness\n",
    "    MIN_FACE_SIZE = 80\n",
    "    MAX_BLUR_SCORE = 100\n",
    "    MAX_POSE_ANGLE = 30\n",
    "    TEXTURE_VARIANCE_MIN = 30\n",
    "    LIVENESS_THRESHOLD = 0.6\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = Path(\"./face_dedup_data\")\n",
    "    AUDIT_LOG_PATH = DATA_DIR / \"audit_logs.jsonl\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "config = Config()\n",
    "print(f\"✓ Configuration initialized | Data dir: {config.DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc08011",
   "metadata": {},
   "source": [
    "## 2. Image Quality Assessment\n",
    "\n",
    "We check image quality before processing to ensure reliable matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityAssessment:\n",
    "    \"\"\"Face image quality assessment module\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load Haar Cascade for fallback face detection\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        self.eye_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
    "        )\n",
    "    \n",
    "    def detect_blur(self, image: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Detect blur using Laplacian variance method\n",
    "        Returns: blur score (higher = sharper)\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        return laplacian_var\n",
    "    \n",
    "    def estimate_pose(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Estimate head pose angles (yaw, pitch, roll)\n",
    "        Simplified version using eye detection\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            return {'yaw': 0, 'pitch': 0, 'roll': 0, 'quality': 'poor'}\n",
    "        \n",
    "        x, y, w, h = faces[0]\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        eyes = self.eye_cascade.detectMultiScale(face_roi, 1.1, 3)\n",
    "        \n",
    "        # Estimate yaw from eye positions\n",
    "        if len(eyes) >= 2:\n",
    "            eye_centers = [(ex + ew//2, ey + eh//2) for ex, ey, ew, eh in eyes[:2]]\n",
    "            eye_centers.sort(key=lambda p: p[0])  # Sort by x-coordinate\n",
    "            \n",
    "            # Calculate roll from eye line angle\n",
    "            dx = eye_centers[1][0] - eye_centers[0][0]\n",
    "            dy = eye_centers[1][1] - eye_centers[0][1]\n",
    "            roll = np.degrees(np.arctan2(dy, dx))\n",
    "            \n",
    "            # Estimate yaw from eye distance asymmetry\n",
    "            eye_dist = dx\n",
    "            expected_dist = w * 0.4\n",
    "            yaw = (eye_dist - expected_dist) / expected_dist * 30  # Rough estimate\n",
    "            \n",
    "            return {'yaw': abs(yaw), 'pitch': 0, 'roll': abs(roll), 'quality': 'good'}\n",
    "        \n",
    "        return {'yaw': 15, 'pitch': 15, 'roll': 0, 'quality': 'moderate'}\n",
    "    \n",
    "    def assess_lighting(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Assess lighting quality\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        mean_brightness = np.mean(gray)\n",
    "        std_brightness = np.std(gray)\n",
    "        \n",
    "        # Check for over/under exposure\n",
    "        over_exposed = np.sum(gray > 250) / gray.size\n",
    "        under_exposed = np.sum(gray < 20) / gray.size\n",
    "        \n",
    "        return {\n",
    "            'mean_brightness': mean_brightness,\n",
    "            'std_brightness': std_brightness,\n",
    "            'over_exposed_ratio': over_exposed,\n",
    "            'under_exposed_ratio': under_exposed,\n",
    "            'quality': 'good' if (40 < mean_brightness < 220 and over_exposed < 0.05) else 'poor'\n",
    "        }\n",
    "    \n",
    "    def comprehensive_assessment(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"Perform comprehensive quality assessment\"\"\"\n",
    "        blur_score = self.detect_blur(image)\n",
    "        pose_info = self.estimate_pose(image)\n",
    "        lighting_info = self.assess_lighting(image)\n",
    "        \n",
    "        # Overall quality score (0-100)\n",
    "        quality_score = 0\n",
    "        \n",
    "        # Blur contribution (40 points)\n",
    "        if blur_score > 500:\n",
    "            quality_score += 40\n",
    "        elif blur_score > 200:\n",
    "            quality_score += 30\n",
    "        elif blur_score > 100:\n",
    "            quality_score += 20\n",
    "        else:\n",
    "            quality_score += 10\n",
    "        \n",
    "        # Pose contribution (30 points)\n",
    "        max_angle = max(pose_info['yaw'], pose_info['pitch'], pose_info['roll'])\n",
    "        if max_angle < 10:\n",
    "            quality_score += 30\n",
    "        elif max_angle < 20:\n",
    "            quality_score += 20\n",
    "        elif max_angle < 30:\n",
    "            quality_score += 10\n",
    "        \n",
    "        # Lighting contribution (30 points)\n",
    "        if lighting_info['quality'] == 'good':\n",
    "            quality_score += 30\n",
    "        elif lighting_info['mean_brightness'] > 40:\n",
    "            quality_score += 15\n",
    "        \n",
    "        decision = 'ACCEPT'\n",
    "        if quality_score < 50:\n",
    "            decision = 'REJECT'\n",
    "        elif quality_score < 70:\n",
    "            decision = 'MANUAL_REVIEW'\n",
    "        \n",
    "        return {\n",
    "            'quality_score': quality_score,\n",
    "            'decision': decision,\n",
    "            'blur_score': blur_score,\n",
    "            'pose': pose_info,\n",
    "            'lighting': lighting_info,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Test the quality assessment\n",
    "qa = QualityAssessment()\n",
    "print(\"✓ Quality Assessment module initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3962e",
   "metadata": {},
   "source": [
    "## 3. Cancelable Biometric Templates\n",
    "\n",
    "Using random projection to create privacy-preserving templates that can be revoked if compromised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelableBiometricTemplate:\n",
    "    \"\"\"\n",
    "    Privacy-preserving template generation using random projection\n",
    "    Aligned with India's DPDP Act principles\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key: bytes = None, input_dim: int = 512, output_dim: int = 256):\n",
    "        self.key = key or config.TEMPLATE_KEY\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Generate deterministic random projection matrix from key\n",
    "        np.random.seed(int.from_bytes(self.key[:4], 'big'))\n",
    "        self.projection_matrix = np.random.randn(input_dim, output_dim).astype(np.float32)\n",
    "        self.projection_matrix = normalize(self.projection_matrix, axis=0)\n",
    "        \n",
    "        # Additional transformation parameters\n",
    "        self.salt = hashlib.sha256(self.key).digest()\n",
    "    \n",
    "    def generate_template(self, embedding: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate cancelable template from face embedding\n",
    "        \n",
    "        Args:\n",
    "            embedding: Original face embedding (512-dim)\n",
    "        \n",
    "        Returns:\n",
    "            Cancelable template (256-dim)\n",
    "        \"\"\"\n",
    "        if len(embedding.shape) == 1:\n",
    "            embedding = embedding.reshape(1, -1)\n",
    "        \n",
    "        # Step 1: Random projection (dimensionality reduction)\n",
    "        projected = np.dot(embedding, self.projection_matrix)\n",
    "        \n",
    "        # Step 2: Normalization\n",
    "        normalized = normalize(projected, axis=1)\n",
    "        \n",
    "        # Step 3: Binarization with key-dependent threshold\n",
    "        threshold = np.sin(int.from_bytes(self.salt[:4], 'big') % 1000 / 1000.0) * 0.5\n",
    "        binary_template = (normalized > threshold).astype(np.float32)\n",
    "        \n",
    "        return binary_template.flatten()\n",
    "    \n",
    "    def revoke_and_regenerate(self, new_key: bytes):\n",
    "        \"\"\"\n",
    "        Revoke current templates and generate new projection\n",
    "        This allows template lifecycle management\n",
    "        \"\"\"\n",
    "        self.key = new_key\n",
    "        np.random.seed(int.from_bytes(self.key[:4], 'big'))\n",
    "        self.projection_matrix = np.random.randn(self.input_dim, self.output_dim).astype(np.float32)\n",
    "        self.projection_matrix = normalize(self.projection_matrix, axis=0)\n",
    "        self.salt = hashlib.sha256(self.key).digest()\n",
    "        \n",
    "        return f\"Templates revoked. New key: {self.key[:8].hex()}...\"\n",
    "    \n",
    "    def compare_templates(self, template1: np.ndarray, template2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compare two cancelable templates\n",
    "        Returns similarity score (0-1)\n",
    "        \"\"\"\n",
    "        # Hamming distance for binary templates\n",
    "        hamming_sim = 1.0 - np.mean(template1 != template2)\n",
    "        return hamming_sim\n",
    "\n",
    "# Initialize cancelable biometric system\n",
    "cancelable_bio = CancelableBiometricTemplate(\n",
    "    input_dim=config.EMBEDDING_DIM,\n",
    "    output_dim=config.CANCELABLE_DIM\n",
    ")\n",
    "\n",
    "print(\"✓ Cancelable Biometric Template system initialized\")\n",
    "print(f\"  - Input dimension: {config.EMBEDDING_DIM}\")\n",
    "print(f\"  - Output dimension: {config.CANCELABLE_DIM}\")\n",
    "print(f\"  - Compression ratio: {config.CANCELABLE_DIM/config.EMBEDDING_DIM:.1%}\")\n",
    "print(f\"  - Key hash: {hashlib.sha256(config.TEMPLATE_KEY).hexdigest()[:16]}...\")\n",
    "\n",
    "# Demonstrate revocability\n",
    "print(\"\\n✓ Demonstrating template revocability:\")\n",
    "print(\"  Original key:\", config.TEMPLATE_KEY[:8].hex() + \"...\")\n",
    "new_key = get_random_bytes(32)\n",
    "result = cancelable_bio.revoke_and_regenerate(new_key)\n",
    "print(f\"  {result}\")\n",
    "# Restore original key for demo\n",
    "cancelable_bio.revoke_and_regenerate(config.TEMPLATE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613596a2",
   "metadata": {},
   "source": [
    "## 4. LSH-Based Fast Search (Stage A)\n",
    "\n",
    "Locality-Sensitive Hashing for quick candidate retrieval from large databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecded6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSHFaceHashIndex:\n",
    "    \"\"\"\n",
    "    Locality-Sensitive Hashing index for fast candidate retrieval\n",
    "    Uses keyed buckets for privacy and auditability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim: int = 256, num_tables: int = 16, num_bits: int = 12):\n",
    "        self.dim = dim\n",
    "        self.num_tables = num_tables\n",
    "        self.num_bits = num_bits\n",
    "        self.num_buckets = 2 ** num_bits\n",
    "        \n",
    "        # Generate random hyperplanes for each hash table\n",
    "        self.hyperplanes = []\n",
    "        for i in range(num_tables):\n",
    "            # Use keyed random generation for security\n",
    "            seed = int.from_bytes(config.HASH_SECRET, 'big') + i\n",
    "            np.random.seed(seed)\n",
    "            planes = np.random.randn(num_bits, dim).astype(np.float32)\n",
    "            planes = normalize(planes, axis=1)\n",
    "            self.hyperplanes.append(planes)\n",
    "        \n",
    "        # Hash tables: table_id -> {bucket_id -> [template_ids]}\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(num_tables)]\n",
    "        \n",
    "        # Template storage: template_id -> template\n",
    "        self.templates = {}\n",
    "        self.metadata = {}  # Store application metadata\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'total_templates': 0,\n",
    "            'queries_processed': 0,\n",
    "            'avg_candidates_per_query': 0\n",
    "        }\n",
    "    \n",
    "    def _compute_hash(self, template: np.ndarray, table_id: int) -> int:\n",
    "        \"\"\"Compute LSH hash for a template using specific hash table\"\"\"\n",
    "        # Project template onto hyperplanes\n",
    "        projections = np.dot(self.hyperplanes[table_id], template)\n",
    "        \n",
    "        # Convert to binary hash\n",
    "        binary_hash = (projections > 0).astype(int)\n",
    "        \n",
    "        # Convert binary to integer bucket ID\n",
    "        bucket_id = int(''.join(binary_hash.astype(str)), 2)\n",
    "        \n",
    "        return bucket_id\n",
    "    \n",
    "    def _create_keyed_bucket(self, table_id: int, bucket_id: int) -> str:\n",
    "        \"\"\"Create a keyed bucket identifier for privacy\"\"\"\n",
    "        # HMAC-based keyed bucket\n",
    "        key_material = f\"{table_id}:{bucket_id}\".encode()\n",
    "        keyed_bucket = hmac.new(config.HASH_SECRET, key_material, hashlib.sha256).hexdigest()[:16]\n",
    "        return keyed_bucket\n",
    "    \n",
    "    def insert(self, template_id: str, template: np.ndarray, metadata: dict = None):\n",
    "        \"\"\"Insert a template into the LSH index\"\"\"\n",
    "        self.templates[template_id] = template\n",
    "        self.metadata[template_id] = metadata or {}\n",
    "        \n",
    "        # Insert into all hash tables\n",
    "        for table_id in range(self.num_tables):\n",
    "            bucket_id = self._compute_hash(template, table_id)\n",
    "            keyed_bucket = self._create_keyed_bucket(table_id, bucket_id)\n",
    "            self.hash_tables[table_id][keyed_bucket].append(template_id)\n",
    "        \n",
    "        self.stats['total_templates'] += 1\n",
    "    \n",
    "    def query(self, query_template: np.ndarray, max_candidates: int = 100) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Query the index for candidate matches\n",
    "        \n",
    "        Returns:\n",
    "            List of (template_id, similarity_score) tuples\n",
    "        \"\"\"\n",
    "        candidate_ids = set()\n",
    "        \n",
    "        # Query all hash tables\n",
    "        for table_id in range(self.num_tables):\n",
    "            bucket_id = self._compute_hash(query_template, table_id)\n",
    "            keyed_bucket = self._create_keyed_bucket(table_id, bucket_id)\n",
    "            \n",
    "            # Get candidates from this bucket\n",
    "            if keyed_bucket in self.hash_tables[table_id]:\n",
    "                candidate_ids.update(self.hash_tables[table_id][keyed_bucket])\n",
    "        \n",
    "        # Calculate actual similarities for candidates\n",
    "        candidates_with_scores = []\n",
    "        for template_id in candidate_ids:\n",
    "            template = self.templates[template_id]\n",
    "            similarity = cancelable_bio.compare_templates(query_template, template)\n",
    "            candidates_with_scores.append((template_id, similarity))\n",
    "        \n",
    "        # Sort by similarity and return top-k\n",
    "        candidates_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        candidates_with_scores = candidates_with_scores[:max_candidates]\n",
    "        \n",
    "        # Update statistics\n",
    "        self.stats['queries_processed'] += 1\n",
    "        self.stats['avg_candidates_per_query'] = (\n",
    "            (self.stats['avg_candidates_per_query'] * (self.stats['queries_processed'] - 1) + \n",
    "             len(candidate_ids)) / self.stats['queries_processed']\n",
    "        )\n",
    "        \n",
    "        return candidates_with_scores\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Get index statistics\"\"\"\n",
    "        bucket_utilization = []\n",
    "        for table in self.hash_tables:\n",
    "            bucket_utilization.append(len(table))\n",
    "        \n",
    "        return {\n",
    "            **self.stats,\n",
    "            'avg_bucket_utilization': np.mean(bucket_utilization),\n",
    "            'max_bucket_size': max([max([len(v) for v in table.values()] + [0]) for table in self.hash_tables])\n",
    "        }\n",
    "\n",
    "# Initialize LSH index\n",
    "lsh_index = LSHFaceHashIndex(\n",
    "    dim=config.CANCELABLE_DIM,\n",
    "    num_tables=config.LSH_NUM_TABLES,\n",
    "    num_bits=config.LSH_NUM_BITS\n",
    ")\n",
    "\n",
    "print(\"✓ LSH FaceHash Index initialized\")\n",
    "print(f\"  - Dimension: {config.CANCELABLE_DIM}\")\n",
    "print(f\"  - Number of hash tables: {config.LSH_NUM_TABLES}\")\n",
    "print(f\"  - Bits per hash: {config.LSH_NUM_BITS}\")\n",
    "print(f\"  - Buckets per table: {lsh_index.num_buckets:,}\")\n",
    "print(f\"  - Total hash space: {lsh_index.num_tables * lsh_index.num_buckets:,} buckets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea0db9",
   "metadata": {},
   "source": [
    "## 5. Deep Face Matching (Stage B)\n",
    "\n",
    "High-precision comparison for shortlisted candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFaceEmbedding:\n",
    "    \"\"\"\n",
    "    Deep face embedding extraction\n",
    "    Simulates ArcFace/CosFace models for prototype\n",
    "    In production: use InsightFace, FaceNet, or ArcFace\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model_name = \"Simulated-ArcFace\"\n",
    "        self.embedding_dim = config.EMBEDDING_DIM\n",
    "        \n",
    "        # For prototype: we'll simulate using traditional features + random projection\n",
    "        # In production, replace with actual deep learning model\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "    \n",
    "    def extract_embedding(self, image: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Extract face embedding from image\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (BGR or grayscale)\n",
    "        \n",
    "        Returns:\n",
    "            512-dim embedding vector or None if no face detected\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        # Detect face\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Get largest face\n",
    "        x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize to standard size\n",
    "        face_resized = cv2.resize(face_roi, (112, 112))\n",
    "        \n",
    "        # PROTOTYPE: Generate simulated embedding\n",
    "        # In production, use actual deep learning model\n",
    "        embedding = self._generate_simulated_embedding(face_resized)\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def _generate_simulated_embedding(self, face: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate simulated face embedding for prototype\n",
    "        Combines: HOG features, LBP, histogram, and structured random components\n",
    "        \"\"\"\n",
    "        # Feature 1: Local Binary Pattern (texture)\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(face, n_points, radius, method='uniform')\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))\n",
    "        lbp_hist = lbp_hist.astype(float) / lbp_hist.sum()\n",
    "        \n",
    "        # Feature 2: Pixel intensity histogram\n",
    "        hist = cv2.calcHist([face], [0], None, [64], [0, 256])\n",
    "        hist = hist.flatten() / hist.sum()\n",
    "        \n",
    "        # Feature 3: Gradient features (HOG-like)\n",
    "        gx = cv2.Sobel(face, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(face, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        grad_hist, _ = np.histogram(magnitude.ravel(), bins=64, range=(0, 256))\n",
    "        grad_hist = grad_hist.astype(float) / grad_hist.sum()\n",
    "        \n",
    "        # Feature 4: Spatial pyramid features\n",
    "        face_top = face[:56, :]\n",
    "        face_bottom = face[56:, :]\n",
    "        hist_top, _ = np.histogram(face_top.ravel(), bins=32, range=(0, 256))\n",
    "        hist_bottom, _ = np.histogram(face_bottom.ravel(), bins=32, range=(0, 256))\n",
    "        spatial_hist = np.concatenate([hist_top, hist_bottom])\n",
    "        spatial_hist = spatial_hist.astype(float) / spatial_hist.sum()\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([lbp_hist, hist, grad_hist, spatial_hist])\n",
    "        \n",
    "        # Pad or project to 512 dimensions\n",
    "        if len(combined_features) < self.embedding_dim:\n",
    "            # Pad with structured random features based on face content\n",
    "            seed = int(np.sum(face.astype(np.int64))) % 100000\n",
    "            np.random.seed(seed)\n",
    "            random_features = np.random.randn(self.embedding_dim - len(combined_features))\n",
    "            embedding = np.concatenate([combined_features, random_features])\n",
    "        else:\n",
    "            embedding = combined_features[:self.embedding_dim]\n",
    "        \n",
    "        # Normalize\n",
    "        embedding = embedding / (np.linalg.norm(embedding) + 1e-8)\n",
    "        \n",
    "        return embedding.astype(np.float32)\n",
    "    \n",
    "    def compare_embeddings(self, emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compare two embeddings using cosine similarity\n",
    "        \n",
    "        Returns:\n",
    "            Similarity score (0-1, higher = more similar)\n",
    "        \"\"\"\n",
    "        # Cosine similarity\n",
    "        similarity = 1.0 - cosine(emb1, emb2)\n",
    "        return max(0.0, min(1.0, similarity))  # Clamp to [0, 1]\n",
    "\n",
    "# Initialize deep face embedding extractor\n",
    "face_embedder = DeepFaceEmbedding()\n",
    "\n",
    "print(\"✓ Deep Face Embedding module initialized\")\n",
    "print(f\"  - Model: {face_embedder.model_name}\")\n",
    "print(f\"  - Embedding dimension: {face_embedder.embedding_dim}\")\n",
    "print(f\"  - Note: Using simulated embeddings for prototype\")\n",
    "print(f\"  - Production: Replace with InsightFace/ArcFace/CosFace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63311102",
   "metadata": {},
   "source": [
    "## 6. Passive Liveness Detection\n",
    "\n",
    "Detecting presentation attacks using texture and frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassiveLivenessDetector:\n",
    "    \"\"\"\n",
    "    Passive liveness detection without user interaction\n",
    "    Detects print attacks, replay attacks, and deepfakes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.texture_threshold = config.TEXTURE_VARIANCE_MIN\n",
    "        self.liveness_threshold = config.LIVENESS_THRESHOLD\n",
    "    \n",
    "    def analyze_texture(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analyze texture to distinguish real skin from print/screen\n",
    "        Real faces have micro-textures not present in prints\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        # Local Binary Pattern for texture analysis\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate texture variance\n",
    "        texture_variance = np.var(lbp)\n",
    "        \n",
    "        # High-frequency content analysis\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        high_freq_energy = np.var(laplacian)\n",
    "        \n",
    "        # Texture richness (histogram entropy)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))\n",
    "        hist = hist.astype(float) / hist.sum()\n",
    "        entropy = -np.sum(hist * np.log2(hist + 1e-10))\n",
    "        \n",
    "        return {\n",
    "            'texture_variance': texture_variance,\n",
    "            'high_freq_energy': high_freq_energy,\n",
    "            'entropy': entropy,\n",
    "            'is_real': texture_variance > self.texture_threshold\n",
    "        }\n",
    "    \n",
    "    def detect_moire_patterns(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Detect moiré patterns (screen replay attacks)\n",
    "        Moiré patterns appear when capturing screens\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        # FFT for frequency analysis\n",
    "        f_transform = np.fft.fft2(gray)\n",
    "        f_shift = np.fft.fftshift(f_transform)\n",
    "        magnitude_spectrum = np.abs(f_shift)\n",
    "        \n",
    "        # Look for periodic patterns in frequency domain\n",
    "        # Moiré patterns create distinct peaks\n",
    "        h, w = magnitude_spectrum.shape\n",
    "        center_region = magnitude_spectrum[h//4:3*h//4, w//4:3*w//4]\n",
    "        outer_region = magnitude_spectrum.copy()\n",
    "        outer_region[h//4:3*h//4, w//4:3*w//4] = 0\n",
    "        \n",
    "        center_energy = np.sum(center_region)\n",
    "        outer_energy = np.sum(outer_region)\n",
    "        \n",
    "        # Calculate periodicity score\n",
    "        if center_energy > 0:\n",
    "            periodicity = outer_energy / center_energy\n",
    "        else:\n",
    "            periodicity = 0\n",
    "        \n",
    "        # Moiré detection: high periodicity indicates screen capture\n",
    "        moire_score = min(periodicity / 0.5, 1.0)  # Normalize\n",
    "        \n",
    "        return {\n",
    "            'periodicity': periodicity,\n",
    "            'moire_score': moire_score,\n",
    "            'has_moire': moire_score > 0.6\n",
    "        }\n",
    "    \n",
    "    def analyze_color_diversity(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analyze color diversity\n",
    "        Real faces have subtle color variations, prints are flatter\n",
    "        \"\"\"\n",
    "        if len(image.shape) != 3:\n",
    "            return {'color_diversity': 0, 'is_diverse': False}\n",
    "        \n",
    "        # Convert to HSV for better color analysis\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Analyze hue and saturation variance\n",
    "        hue_var = np.var(hsv[:, :, 0])\n",
    "        sat_var = np.var(hsv[:, :, 1])\n",
    "        val_var = np.var(hsv[:, :, 2])\n",
    "        \n",
    "        # Color diversity score\n",
    "        color_diversity = (hue_var + sat_var + val_var) / 3\n",
    "        \n",
    "        return {\n",
    "            'hue_variance': hue_var,\n",
    "            'saturation_variance': sat_var,\n",
    "            'value_variance': val_var,\n",
    "            'color_diversity': color_diversity,\n",
    "            'is_diverse': color_diversity > 100\n",
    "        }\n",
    "    \n",
    "    def check_reflection_consistency(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Check for reflection consistency\n",
    "        3D masks and prints have inconsistent lighting/reflections\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        # Divide face into regions\n",
    "        h, w = gray.shape\n",
    "        regions = [\n",
    "            gray[:h//2, :w//2],      # Top-left\n",
    "            gray[:h//2, w//2:],      # Top-right\n",
    "            gray[h//2:, :w//2],      # Bottom-left\n",
    "            gray[h//2:, w//2:]       # Bottom-right\n",
    "        ]\n",
    "        \n",
    "        # Calculate mean brightness in each region\n",
    "        region_means = [np.mean(r) for r in regions]\n",
    "        \n",
    "        # Reflection consistency: low variance = suspicious\n",
    "        brightness_variance = np.var(region_means)\n",
    "        \n",
    "        return {\n",
    "            'brightness_variance': brightness_variance,\n",
    "            'is_consistent': brightness_variance > 50\n",
    "        }\n",
    "    \n",
    "    def comprehensive_liveness_check(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform comprehensive passive liveness detection\n",
    "        \"\"\"\n",
    "        texture_result = self.analyze_texture(image)\n",
    "        moire_result = self.detect_moire_patterns(image)\n",
    "        color_result = self.analyze_color_diversity(image)\n",
    "        reflection_result = self.check_reflection_consistency(image)\n",
    "        \n",
    "        # Calculate overall liveness score (0-1)\n",
    "        score = 0\n",
    "        \n",
    "        # Texture contribution (40%)\n",
    "        if texture_result['is_real']:\n",
    "            score += 0.4\n",
    "        else:\n",
    "            score += 0.2 * (texture_result['texture_variance'] / self.texture_threshold)\n",
    "        \n",
    "        # Moiré contribution (30%)\n",
    "        if not moire_result['has_moire']:\n",
    "            score += 0.3\n",
    "        else:\n",
    "            score += 0.3 * (1 - moire_result['moire_score'])\n",
    "        \n",
    "        # Color diversity contribution (20%)\n",
    "        if color_result['is_diverse']:\n",
    "            score += 0.2\n",
    "        else:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Reflection consistency (10%)\n",
    "        if reflection_result['is_consistent']:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Decision\n",
    "        if score >= 0.7:\n",
    "            decision = 'LIVE'\n",
    "        elif score >= 0.4:\n",
    "            decision = 'UNCERTAIN'\n",
    "        else:\n",
    "            decision = 'SPOOF'\n",
    "        \n",
    "        return {\n",
    "            'liveness_score': score,\n",
    "            'decision': decision,\n",
    "            'texture_analysis': texture_result,\n",
    "            'moire_detection': moire_result,\n",
    "            'color_analysis': color_result,\n",
    "            'reflection_analysis': reflection_result,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Initialize liveness detector\n",
    "liveness_detector = PassiveLivenessDetector()\n",
    "\n",
    "print(\"✓ Passive Liveness Detector initialized\")\n",
    "print(f\"  - Texture variance threshold: {config.TEXTURE_VARIANCE_MIN}\")\n",
    "print(f\"  - Liveness confidence threshold: {config.LIVENESS_THRESHOLD}\")\n",
    "print(\"  - Detection methods:\")\n",
    "print(\"    • Texture analysis (LBP, high-freq content)\")\n",
    "print(\"    • Moiré pattern detection (FFT)\")\n",
    "print(\"    • Color diversity analysis\")\n",
    "print(\"    • Reflection consistency check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4285547",
   "metadata": {},
   "source": [
    "## 7. Audit Logging\n",
    "\n",
    "Immutable audit trail for transparency and compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuditLogger:\n",
    "    \"\"\"\n",
    "    Immutable audit trail system\n",
    "    Compliant with India's DPDP Act requirements\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_path: Path = None):\n",
    "        self.log_path = log_path or config.AUDIT_LOG_PATH\n",
    "        self.log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def log_event(self, event_type: str, event_data: dict):\n",
    "        \"\"\"\n",
    "        Log an event to the audit trail\n",
    "        \n",
    "        Event types:\n",
    "        - APPLICATION_SUBMITTED\n",
    "        - QUALITY_CHECK\n",
    "        - LIVENESS_CHECK\n",
    "        - TEMPLATE_GENERATED\n",
    "        - DUPLICATE_SEARCH\n",
    "        - MATCH_DECISION\n",
    "        - MANUAL_REVIEW\n",
    "        - TEMPLATE_REVOKED\n",
    "        \"\"\"\n",
    "        event = {\n",
    "            'event_id': str(uuid.uuid4()),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'event_type': event_type,\n",
    "            'data': event_data\n",
    "        }\n",
    "        \n",
    "        # Append to log file (append-only)\n",
    "        with open(self.log_path, 'a') as f:\n",
    "            f.write(json.dumps(event) + '\\n')\n",
    "    \n",
    "    def log_application_intake(self, application_id: str, metadata: dict):\n",
    "        \"\"\"Log new application submission\"\"\"\n",
    "        self.log_event('APPLICATION_SUBMITTED', {\n",
    "            'application_id': application_id,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    \n",
    "    def log_quality_check(self, application_id: str, quality_result: dict):\n",
    "        \"\"\"Log quality assessment result\"\"\"\n",
    "        self.log_event('QUALITY_CHECK', {\n",
    "            'application_id': application_id,\n",
    "            'quality_score': quality_result['quality_score'],\n",
    "            'decision': quality_result['decision'],\n",
    "            'details': quality_result\n",
    "        })\n",
    "    \n",
    "    def log_liveness_check(self, application_id: str, liveness_result: dict):\n",
    "        \"\"\"Log liveness detection result\"\"\"\n",
    "        self.log_event('LIVENESS_CHECK', {\n",
    "            'application_id': application_id,\n",
    "            'liveness_score': liveness_result['liveness_score'],\n",
    "            'decision': liveness_result['decision'],\n",
    "            'details': liveness_result\n",
    "        })\n",
    "    \n",
    "    def log_template_generation(self, application_id: str, template_id: str):\n",
    "        \"\"\"Log template generation\"\"\"\n",
    "        self.log_event('TEMPLATE_GENERATED', {\n",
    "            'application_id': application_id,\n",
    "            'template_id': template_id,\n",
    "            'template_type': 'cancelable_biometric'\n",
    "        })\n",
    "    \n",
    "    def log_duplicate_search(self, application_id: str, num_candidates: int, search_time: float):\n",
    "        \"\"\"Log duplicate search operation\"\"\"\n",
    "        self.log_event('DUPLICATE_SEARCH', {\n",
    "            'application_id': application_id,\n",
    "            'num_candidates_found': num_candidates,\n",
    "            'search_time_ms': search_time * 1000\n",
    "        })\n",
    "    \n",
    "    def log_match_decision(self, application_id: str, match_result: dict):\n",
    "        \"\"\"Log matching decision\"\"\"\n",
    "        self.log_event('MATCH_DECISION', {\n",
    "            'application_id': application_id,\n",
    "            'decision': match_result['decision'],\n",
    "            'confidence': match_result.get('confidence', 0),\n",
    "            'matched_applications': match_result.get('matches', [])\n",
    "        })\n",
    "    \n",
    "    def log_manual_review(self, application_id: str, reviewer_id: str, decision: str, justification: str):\n",
    "        \"\"\"Log manual review decision\"\"\"\n",
    "        self.log_event('MANUAL_REVIEW', {\n",
    "            'application_id': application_id,\n",
    "            'reviewer_id': reviewer_id,\n",
    "            'decision': decision,\n",
    "            'justification': justification\n",
    "        })\n",
    "    \n",
    "    def log_template_revocation(self, template_id: str, reason: str):\n",
    "        \"\"\"Log template revocation\"\"\"\n",
    "        self.log_event('TEMPLATE_REVOKED', {\n",
    "            'template_id': template_id,\n",
    "            'reason': reason\n",
    "        })\n",
    "    \n",
    "    def get_audit_trail(self, application_id: str = None) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Retrieve audit trail for an application or all events\n",
    "        \"\"\"\n",
    "        if not self.log_path.exists():\n",
    "            return []\n",
    "        \n",
    "        events = []\n",
    "        with open(self.log_path, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    event = json.loads(line.strip())\n",
    "                    if application_id is None or event['data'].get('application_id') == application_id:\n",
    "                        events.append(event)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return events\n",
    "    \n",
    "    def generate_audit_report(self) -> dict:\n",
    "        \"\"\"Generate summary audit report\"\"\"\n",
    "        events = self.get_audit_trail()\n",
    "        \n",
    "        event_counts = defaultdict(int)\n",
    "        for event in events:\n",
    "            event_counts[event['event_type']] += 1\n",
    "        \n",
    "        return {\n",
    "            'total_events': len(events),\n",
    "            'event_breakdown': dict(event_counts),\n",
    "            'first_event': events[0]['timestamp'] if events else None,\n",
    "            'last_event': events[-1]['timestamp'] if events else None\n",
    "        }\n",
    "\n",
    "# Initialize audit logger\n",
    "audit_logger = AuditLogger()\n",
    "\n",
    "print(\"✓ Audit Logger initialized\")\n",
    "print(f\"  - Log path: {audit_logger.log_path}\")\n",
    "print(f\"  - Format: JSONL (append-only)\")\n",
    "print(f\"  - Event types: APPLICATION_SUBMITTED, QUALITY_CHECK, LIVENESS_CHECK,\")\n",
    "print(f\"                 TEMPLATE_GENERATED, DUPLICATE_SEARCH, MATCH_DECISION,\")\n",
    "print(f\"                 MANUAL_REVIEW, TEMPLATE_REVOKED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb5ade",
   "metadata": {},
   "source": [
    "## 8. Complete Pipeline\n",
    "\n",
    "Putting it all together: quality check → liveness → embedding → LSH search → deep matching → decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDeduplicationPipeline:\n",
    "    \"\"\"\n",
    "    Complete end-to-end face de-duplication system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa = qa\n",
    "        self.liveness_detector = liveness_detector\n",
    "        self.face_embedder = face_embedder\n",
    "        self.cancelable_bio = cancelable_bio\n",
    "        self.lsh_index = lsh_index\n",
    "        self.audit_logger = audit_logger\n",
    "        \n",
    "        # Application database\n",
    "        self.applications = {}\n",
    "        self.embeddings = {}  # Store original embeddings for Stage B\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'total_applications': 0,\n",
    "            'accepted': 0,\n",
    "            'rejected_quality': 0,\n",
    "            'rejected_liveness': 0,\n",
    "            'duplicates_found': 0,\n",
    "            'manual_reviews': 0\n",
    "        }\n",
    "    \n",
    "    def process_application(self, image: np.ndarray, metadata: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Process a new application through the complete pipeline\n",
    "        \n",
    "        Args:\n",
    "            image: Face image\n",
    "            metadata: Application metadata (name, exam, date, etc.)\n",
    "        \n",
    "        Returns:\n",
    "            Processing result with decision and details\n",
    "        \"\"\"\n",
    "        application_id = str(uuid.uuid4())\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Log application intake\n",
    "        self.audit_logger.log_application_intake(application_id, metadata)\n",
    "        self.stats['total_applications'] += 1\n",
    "        \n",
    "        # Stage 0: Quality Assessment\n",
    "        quality_result = self.qa.comprehensive_assessment(image)\n",
    "        self.audit_logger.log_quality_check(application_id, quality_result)\n",
    "        \n",
    "        if quality_result['decision'] == 'REJECT':\n",
    "            self.stats['rejected_quality'] += 1\n",
    "            return {\n",
    "                'application_id': application_id,\n",
    "                'status': 'REJECTED',\n",
    "                'reason': 'Poor image quality',\n",
    "                'quality_assessment': quality_result,\n",
    "                'processing_time': time.time() - start_time\n",
    "            }\n",
    "        \n",
    "        # Stage 1: Liveness Detection\n",
    "        liveness_result = self.liveness_detector.comprehensive_liveness_check(image)\n",
    "        self.audit_logger.log_liveness_check(application_id, liveness_result)\n",
    "        \n",
    "        if liveness_result['decision'] == 'SPOOF':\n",
    "            self.stats['rejected_liveness'] += 1\n",
    "            return {\n",
    "                'application_id': application_id,\n",
    "                'status': 'REJECTED',\n",
    "                'reason': 'Suspected spoof attack',\n",
    "                'liveness_assessment': liveness_result,\n",
    "                'processing_time': time.time() - start_time\n",
    "            }\n",
    "        \n",
    "        # Stage 2: Extract Face Embedding\n",
    "        embedding = self.face_embedder.extract_embedding(image)\n",
    "        \n",
    "        if embedding is None:\n",
    "            self.stats['rejected_quality'] += 1\n",
    "            return {\n",
    "                'application_id': application_id,\n",
    "                'status': 'REJECTED',\n",
    "                'reason': 'No face detected',\n",
    "                'processing_time': time.time() - start_time\n",
    "            }\n",
    "        \n",
    "        # Store original embedding for Stage B\n",
    "        self.embeddings[application_id] = embedding\n",
    "        \n",
    "        # Stage A: Generate Cancelable Template and Search\n",
    "        cancelable_template = self.cancelable_bio.generate_template(embedding)\n",
    "        \n",
    "        template_id = f\"TPL-{application_id[:8]}\"\n",
    "        self.audit_logger.log_template_generation(application_id, template_id)\n",
    "        \n",
    "        # Search for duplicates using LSH\n",
    "        search_start = time.time()\n",
    "        candidates = self.lsh_index.query(cancelable_template, max_candidates=config.MAX_CANDIDATES_PER_QUERY)\n",
    "        search_time = time.time() - search_start\n",
    "        \n",
    "        self.audit_logger.log_duplicate_search(application_id, len(candidates), search_time)\n",
    "        \n",
    "        # Stage B: High-precision re-ranking\n",
    "        matches = []\n",
    "        for candidate_id, stage_a_score in candidates:\n",
    "            if candidate_id in self.embeddings:\n",
    "                # Deep embedding comparison\n",
    "                candidate_embedding = self.embeddings[candidate_id]\n",
    "                stage_b_score = self.face_embedder.compare_embeddings(embedding, candidate_embedding)\n",
    "                \n",
    "                # Combined score (weighted average)\n",
    "                combined_score = 0.3 * stage_a_score + 0.7 * stage_b_score\n",
    "                \n",
    "                matches.append({\n",
    "                    'application_id': candidate_id,\n",
    "                    'stage_a_score': float(stage_a_score),\n",
    "                    'stage_b_score': float(stage_b_score),\n",
    "                    'combined_score': float(combined_score),\n",
    "                    'metadata': self.applications.get(candidate_id, {})\n",
    "                })\n",
    "        \n",
    "        # Sort by combined score\n",
    "        matches.sort(key=lambda x: x['combined_score'], reverse=True)\n",
    "        \n",
    "        # Risk-based Decision\n",
    "        decision_result = self._make_decision(matches, quality_result, liveness_result)\n",
    "        \n",
    "        self.audit_logger.log_match_decision(application_id, decision_result)\n",
    "        \n",
    "        # Update statistics\n",
    "        if decision_result['decision'] == 'UNIQUE':\n",
    "            # Insert into database\n",
    "            self.lsh_index.insert(application_id, cancelable_template, metadata)\n",
    "            self.applications[application_id] = metadata\n",
    "            self.stats['accepted'] += 1\n",
    "        elif decision_result['decision'] == 'DUPLICATE':\n",
    "            self.stats['duplicates_found'] += 1\n",
    "        elif decision_result['decision'] == 'MANUAL_REVIEW':\n",
    "            self.stats['manual_reviews'] += 1\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            'application_id': application_id,\n",
    "            'status': decision_result['decision'],\n",
    "            'quality_assessment': quality_result,\n",
    "            'liveness_assessment': liveness_result,\n",
    "            'duplicate_check': {\n",
    "                'candidates_found': len(candidates),\n",
    "                'matches_analyzed': len(matches),\n",
    "                'top_matches': matches[:5],\n",
    "                'search_time_ms': search_time * 1000\n",
    "            },\n",
    "            'decision': decision_result,\n",
    "            'processing_time': processing_time\n",
    "        }\n",
    "    \n",
    "    def _make_decision(self, matches: List[dict], quality: dict, liveness: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Risk-based decision making with abstention\n",
    "        \"\"\"\n",
    "        if not matches:\n",
    "            # No candidates found - unique application\n",
    "            return {\n",
    "                'decision': 'UNIQUE',\n",
    "                'confidence': 1.0,\n",
    "                'reason': 'No similar applications found'\n",
    "            }\n",
    "        \n",
    "        top_match = matches[0]\n",
    "        top_score = top_match['combined_score']\n",
    "        \n",
    "        # Adjust thresholds based on quality and liveness\n",
    "        quality_factor = quality['quality_score'] / 100\n",
    "        liveness_factor = liveness['liveness_score']\n",
    "        confidence_factor = (quality_factor + liveness_factor) / 2\n",
    "        \n",
    "        adjusted_high = config.MATCH_THRESHOLD_HIGH * confidence_factor\n",
    "        adjusted_low = config.MATCH_THRESHOLD_LOW * confidence_factor\n",
    "        \n",
    "        if top_score >= adjusted_high:\n",
    "            # High confidence duplicate\n",
    "            return {\n",
    "                'decision': 'DUPLICATE',\n",
    "                'confidence': top_score,\n",
    "                'reason': f'High similarity ({top_score:.2%}) with existing application',\n",
    "                'matches': [top_match]\n",
    "            }\n",
    "        elif top_score <= adjusted_low:\n",
    "            # High confidence unique\n",
    "            return {\n",
    "                'decision': 'UNIQUE',\n",
    "                'confidence': 1.0 - top_score,\n",
    "                'reason': f'Low similarity ({top_score:.2%}) with all applications'\n",
    "            }\n",
    "        else:\n",
    "            # Uncertain - send to manual review\n",
    "            return {\n",
    "                'decision': 'MANUAL_REVIEW',\n",
    "                'confidence': 0.5,\n",
    "                'reason': f'Uncertain match ({top_score:.2%}) - requires human review',\n",
    "                'matches': matches[:3]\n",
    "            }\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"Get pipeline statistics\"\"\"\n",
    "        total = self.stats['total_applications']\n",
    "        if total == 0:\n",
    "            return self.stats\n",
    "        \n",
    "        return {\n",
    "            **self.stats,\n",
    "            'acceptance_rate': self.stats['accepted'] / total,\n",
    "            'duplicate_rate': self.stats['duplicates_found'] / total,\n",
    "            'manual_review_rate': self.stats['manual_reviews'] / total,\n",
    "            'quality_rejection_rate': self.stats['rejected_quality'] / total,\n",
    "            'liveness_rejection_rate': self.stats['rejected_liveness'] / total\n",
    "        }\n",
    "\n",
    "# Initialize the complete pipeline\n",
    "dedup_pipeline = FaceDeduplicationPipeline()\n",
    "\n",
    "print(\"✓ Face De-duplication Pipeline initialized\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Pipeline Stages:\")\n",
    "print(\"  1. Quality Assessment (blur, pose, lighting)\")\n",
    "print(\"  2. Liveness Detection (texture, moiré, reflection)\")\n",
    "print(\"  3. Face Embedding Extraction\")\n",
    "print(\"  4. Stage A: Cancelable Template + LSH Blocking\")\n",
    "print(\"  5. Stage B: Deep Embedding Re-ranking\")\n",
    "print(\"  6. Risk-based Decision (UNIQUE/DUPLICATE/MANUAL_REVIEW)\")\n",
    "print(\"  7. Audit Logging\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b274c",
   "metadata": {},
   "source": [
    "## 9. Load LFW Dataset for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_lfw_dataset():\n",
    "    \"\"\"Download and extract LFW dataset\"\"\"\n",
    "    lfw_dir = config.DATA_DIR / \"lfw\"\n",
    "    \n",
    "    if lfw_dir.exists() and len(list(lfw_dir.glob(\"*/*.jpg\"))) > 100:\n",
    "        print(f\"✓ LFW dataset already available\")\n",
    "        return lfw_dir\n",
    "    \n",
    "    print(\"Downloading LFW dataset (this may take a few minutes)...\")\n",
    "    lfw_url = \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\"\n",
    "    tgz_path = config.DATA_DIR / \"lfw.tgz\"\n",
    "    \n",
    "    try:\n",
    "        if not tgz_path.exists():\n",
    "            urllib.request.urlretrieve(lfw_url, tgz_path)\n",
    "        \n",
    "        print(\"Extracting...\")\n",
    "        with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "            tar.extractall(config.DATA_DIR)\n",
    "        \n",
    "        tgz_path.unlink()\n",
    "        print(f\"✓ LFW dataset ready\")\n",
    "        return lfw_dir\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_test_applications(lfw_dir, num_apps=30, duplicate_ratio=0.3):\n",
    "    \"\"\"Prepare test applications from LFW dataset\"\"\"\n",
    "    # Get people with multiple images\n",
    "    person_images = defaultdict(list)\n",
    "    \n",
    "    for person_dir in lfw_dir.iterdir():\n",
    "        if person_dir.is_dir():\n",
    "            images = list(person_dir.glob(\"*.jpg\"))\n",
    "            if len(images) > 0:\n",
    "                person_images[person_dir.name] = [str(p) for p in images]\n",
    "    \n",
    "    # Filter people with 2+ images for duplicates\n",
    "    multi_image_people = {k: v for k, v in person_images.items() if len(v) >= 2}\n",
    "    \n",
    "    applications = []\n",
    "    num_duplicates = int(num_apps * duplicate_ratio)\n",
    "    num_unique = num_apps - num_duplicates\n",
    "    \n",
    "    # Add unique applications\n",
    "    people = list(person_images.keys())\n",
    "    np.random.shuffle(people)\n",
    "    \n",
    "    for i, person in enumerate(people[:num_unique]):\n",
    "        img_path = person_images[person][0]\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is not None:\n",
    "            applications.append({\n",
    "                'image': image,\n",
    "                'metadata': {\n",
    "                    'name': f\"Applicant_{i+1:03d}\",\n",
    "                    'person_id': person,\n",
    "                    'exam': np.random.choice(['UPSC', 'SSC', 'Railway', 'Banking']),\n",
    "                    'date': f\"2025-{np.random.randint(1, 3):02d}-15\",\n",
    "                    'ground_truth': 'unique'\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Add duplicate pairs\n",
    "    dup_people = list(multi_image_people.keys())\n",
    "    np.random.shuffle(dup_people)\n",
    "    \n",
    "    for i, person in enumerate(dup_people[:num_duplicates//2]):\n",
    "        images = person_images[person][:2]\n",
    "        \n",
    "        img1 = cv2.imread(images[0])\n",
    "        img2 = cv2.imread(images[1])\n",
    "        \n",
    "        if img1 is not None and img2 is not None:\n",
    "            base_id = len(applications) + 1\n",
    "            \n",
    "            applications.append({\n",
    "                'image': img1,\n",
    "                'metadata': {\n",
    "                    'name': f\"Applicant_{base_id:03d}\",\n",
    "                    'person_id': person,\n",
    "                    'exam': 'UPSC',\n",
    "                    'date': '2025-01-15',\n",
    "                    'ground_truth': 'unique'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            applications.append({\n",
    "                'image': img2,\n",
    "                'metadata': {\n",
    "                    'name': f\"Applicant_{base_id:03d}_DUP\",\n",
    "                    'person_id': person,\n",
    "                    'exam': 'SSC',\n",
    "                    'date': '2025-02-20',\n",
    "                    'ground_truth': 'duplicate'\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    print(f\"✓ Prepared {len(applications)} test applications\")\n",
    "    return applications\n",
    "\n",
    "# Load dataset\n",
    "lfw_dir = download_lfw_dataset()\n",
    "if lfw_dir:\n",
    "    test_applications = prepare_test_applications(lfw_dir, num_apps=30, duplicate_ratio=0.3)\n",
    "else:\n",
    "    print(\"Could not load LFW dataset\")\n",
    "    test_applications = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611061d0",
   "metadata": {},
   "source": [
    "## 10. Process Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process applications through the pipeline\n",
    "results = []\n",
    "print(f\"Processing {len(test_applications)} applications...\\n\")\n",
    "\n",
    "for i, app in enumerate(test_applications):\n",
    "    result = dedup_pipeline.process_application(app['image'], app['metadata'])\n",
    "    results.append(result)\n",
    "    \n",
    "    # Log for fairness analysis\n",
    "    if 'quality_assessment' in result and 'liveness_assessment' in result:\n",
    "        match_score = 0\n",
    "        if 'duplicate_check' in result and result['duplicate_check']['top_matches']:\n",
    "            match_score = result['duplicate_check']['top_matches'][0]['combined_score']\n",
    "        \n",
    "        fairness_analyzer.log_result(\n",
    "            image=app['image'],\n",
    "            ground_truth=app['metadata']['ground_truth'],\n",
    "            prediction=result['decision']['decision'] if 'decision' in result else 'REJECTED',\n",
    "            quality_score=result['quality_assessment']['quality_score'],\n",
    "            liveness_score=result['liveness_assessment']['liveness_score'],\n",
    "            match_score=match_score\n",
    "        )\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(test_applications)} applications\")\n",
    "\n",
    "print(f\"\\n✓ All applications processed\")\n",
    "\n",
    "# Calculate accuracy\n",
    "tp = fp = tn = fn = 0\n",
    "for app, result in zip(test_applications, results):\n",
    "    gt = app['metadata']['ground_truth']\n",
    "    pred = result['decision']['decision'] if 'decision' in result else 'REJECTED'\n",
    "    \n",
    "    if gt == 'duplicate' and pred == 'DUPLICATE':\n",
    "        tp += 1\n",
    "    elif gt == 'unique' and pred == 'DUPLICATE':\n",
    "        fp += 1\n",
    "    elif gt == 'duplicate' and pred == 'UNIQUE':\n",
    "        fn += 1\n",
    "    elif gt == 'unique' and pred == 'UNIQUE':\n",
    "        tn += 1\n",
    "\n",
    "total = tp + fp + tn + fn\n",
    "accuracy = (tp + tn) / total if total > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nAccuracy Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy:.2%}\")\n",
    "print(f\"  Precision: {precision:.2%}\")\n",
    "print(f\"  Recall:    {recall:.2%}\")\n",
    "print(f\"  F1-Score:  {f1:.2%}\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  TP: {tp} | FP: {fp}\")\n",
    "print(f\"  FN: {fn} | TN: {tn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and visualize duplicate pairs\n",
    "duplicate_pairs = []\n",
    "for i, result in enumerate(results):\n",
    "    if 'decision' in result and result['decision']['decision'] == 'DUPLICATE':\n",
    "        if 'duplicate_check' in result and result['duplicate_check']['top_matches']:\n",
    "            top_match = result['duplicate_check']['top_matches'][0]\n",
    "            matched_id = top_match['application_id']\n",
    "            \n",
    "            for j, res in enumerate(results):\n",
    "                if res['application_id'] == matched_id:\n",
    "                    duplicate_pairs.append({\n",
    "                        'query_idx': i,\n",
    "                        'match_idx': j,\n",
    "                        'similarity': top_match['combined_score']\n",
    "                    })\n",
    "                    break\n",
    "\n",
    "if duplicate_pairs:\n",
    "    print(f\"Found {len(duplicate_pairs)} duplicate pairs\\n\")\n",
    "    \n",
    "    # Show top 3 pairs\n",
    "    num_show = min(3, len(duplicate_pairs))\n",
    "    fig, axes = plt.subplots(num_show, 3, figsize=(15, 5 * num_show))\n",
    "    \n",
    "    if num_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, pair in enumerate(duplicate_pairs[:num_show]):\n",
    "        query_app = test_applications[pair['query_idx']]\n",
    "        match_app = test_applications[pair['match_idx']]\n",
    "        \n",
    "        # Query image\n",
    "        axes[idx, 0].imshow(cv2.cvtColor(query_app['image'], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx, 0].set_title(f\"{query_app['metadata']['name']}\\n{query_app['metadata']['person_id']}\")\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Match image\n",
    "        axes[idx, 1].imshow(cv2.cvtColor(match_app['image'], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx, 1].set_title(f\"{match_app['metadata']['name']}\\n{match_app['metadata']['person_id']}\")\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        # Similarity\n",
    "        axes[idx, 2].barh(['Similarity'], [pair['similarity'] * 100], color='#e74c3c')\n",
    "        axes[idx, 2].set_xlim(0, 100)\n",
    "        axes[idx, 2].set_xlabel('Score (%)')\n",
    "        axes[idx, 2].axvline(x=85, color='green', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Verdict\n",
    "        same_person = query_app['metadata']['person_id'] == match_app['metadata']['person_id']\n",
    "        verdict = \"✓ Correct\" if same_person else \"✗ False Positive\"\n",
    "        axes[idx, 2].text(50, 0, verdict, ha='center', va='center', \n",
    "                         color='green' if same_person else 'red', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No duplicates detected in this run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9e161",
   "metadata": {},
   "source": [
    "## 12. System Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline statistics\n",
    "pipeline_stats = dedup_pipeline.get_statistics()\n",
    "\n",
    "print(\"Pipeline Statistics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Applications: {pipeline_stats['total_applications']}\")\n",
    "print(f\"Accepted: {pipeline_stats['accepted']}\")\n",
    "print(f\"Duplicates Found: {pipeline_stats['duplicates_found']}\")\n",
    "print(f\"Manual Reviews: {pipeline_stats['manual_reviews']}\")\n",
    "print(f\"Rejected (Quality): {pipeline_stats['rejected_quality']}\")\n",
    "print(f\"Rejected (Liveness): {pipeline_stats['rejected_liveness']}\")\n",
    "\n",
    "if pipeline_stats['total_applications'] > 0:\n",
    "    print(f\"\\nRates:\")\n",
    "    print(f\"  Duplicate Rate: {pipeline_stats['duplicate_rate']:.1%}\")\n",
    "    print(f\"  Quality Rejection: {pipeline_stats['quality_rejection_rate']:.1%}\")\n",
    "\n",
    "# LSH performance\n",
    "lsh_stats = lsh_index.get_statistics()\n",
    "print(f\"\\nLSH Index:\")\n",
    "print(f\"  Templates: {lsh_stats['total_templates']}\")\n",
    "print(f\"  Avg Candidates/Query: {lsh_stats['avg_candidates_per_query']:.1f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Outcomes\n",
    "outcomes = {\n",
    "    'Accepted': pipeline_stats['accepted'],\n",
    "    'Duplicates': pipeline_stats['duplicates_found'],\n",
    "    'Manual Review': pipeline_stats['manual_reviews'],\n",
    "    'Rejected': pipeline_stats['rejected_quality'] + pipeline_stats['rejected_liveness']\n",
    "}\n",
    "outcomes = {k: v for k, v in outcomes.items() if v > 0}\n",
    "\n",
    "axes[0].pie(outcomes.values(), labels=outcomes.keys(), autopct='%1.1f%%')\n",
    "axes[0].set_title('Application Outcomes')\n",
    "\n",
    "# Processing stages\n",
    "audit_report = audit_logger.generate_audit_report()\n",
    "stages = list(audit_report['event_breakdown'].keys())\n",
    "counts = list(audit_report['event_breakdown'].values())\n",
    "\n",
    "axes[1].bar(stages, counts, color='#3498db')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Processing Events')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71d18e",
   "metadata": {},
   "source": [
    "## 13. Explainability Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d249f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explainability_dashboard(result: dict, image: np.ndarray):\n",
    "    \"\"\"Create dashboard for human review\"\"\"\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Original Image\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Application Image', fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Quality Metrics\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    qa = result.get('quality_assessment', {})\n",
    "    quality_metrics = {\n",
    "        'Overall': qa.get('quality_score', 0),\n",
    "        'Sharpness': min(qa.get('blur_score', 0) / 5, 100),\n",
    "        'Lighting': 100 if qa.get('lighting', {}).get('quality') == 'good' else 50,\n",
    "        'Pose': 100 - min(qa.get('pose', {}).get('yaw', 30) * 3, 100)\n",
    "    }\n",
    "    \n",
    "    colors = ['#2ecc71' if v > 70 else '#f39c12' if v > 50 else '#e74c3c' \n",
    "              for v in quality_metrics.values()]\n",
    "    ax2.barh(list(quality_metrics.keys()), list(quality_metrics.values()), color=colors)\n",
    "    ax2.set_xlim(0, 100)\n",
    "    ax2.set_title('Quality Assessment', fontweight='bold')\n",
    "    \n",
    "    # Liveness Score\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    la = result.get('liveness_assessment', {})\n",
    "    liveness_score = la.get('liveness_score', 0) * 100\n",
    "    \n",
    "    color = '#2ecc71' if liveness_score > 70 else '#f39c12' if liveness_score > 40 else '#e74c3c'\n",
    "    ax3.pie([liveness_score, 100 - liveness_score], colors=[color, '#ecf0f1'],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    ax3.set_title(f'Liveness\\n{la.get(\"decision\", \"N/A\")}', fontweight='bold')\n",
    "    \n",
    "    # Duplicate Matches\n",
    "    ax4 = fig.add_subplot(gs[1, :])\n",
    "    dc = result.get('duplicate_check', {})\n",
    "    top_matches = dc.get('top_matches', [])[:5]\n",
    "    \n",
    "    if top_matches:\n",
    "        match_ids = [f\"Match {i+1}\" for i in range(len(top_matches))]\n",
    "        combined = [m['combined_score'] * 100 for m in top_matches]\n",
    "        \n",
    "        ax4.bar(match_ids, combined, color='#e74c3c')\n",
    "        ax4.axhline(y=85, color='green', linestyle='--', label='Match Threshold')\n",
    "        ax4.axhline(y=65, color='orange', linestyle='--', label='Review Threshold')\n",
    "        ax4.set_ylabel('Similarity (%)')\n",
    "        ax4.set_title('Top Candidate Matches', fontweight='bold')\n",
    "        ax4.legend()\n",
    "        ax4.set_ylim(0, 100)\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No duplicates found', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=14)\n",
    "        ax4.axis('off')\n",
    "    \n",
    "    # Decision\n",
    "    ax5 = fig.add_subplot(gs[2, :])\n",
    "    decision = result.get('decision', {})\n",
    "    dec_text = f\"DECISION: {decision.get('decision', 'N/A')}\\n\\n\"\n",
    "    dec_text += f\"Confidence: {decision.get('confidence', 0):.1%}\\n\\n\"\n",
    "    dec_text += f\"Reason: {decision.get('reason', 'N/A')}\"\n",
    "    \n",
    "    dec_color = '#2ecc71' if decision.get('decision') == 'UNIQUE' else \\\n",
    "                '#e74c3c' if decision.get('decision') == 'DUPLICATE' else '#f39c12'\n",
    "    \n",
    "    ax5.text(0.5, 0.5, dec_text, ha='center', va='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor=dec_color, alpha=0.3),\n",
    "            transform=ax5.transAxes)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    plt.suptitle('Explainability Dashboard', fontsize=16, fontweight='bold')\n",
    "    return fig\n",
    "\n",
    "# Create dashboard for first result\n",
    "if results:\n",
    "    dashboard = create_explainability_dashboard(results[0], test_applications[0]['image'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b90ae",
   "metadata": {},
   "source": [
    "## 14. Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze system performance across demographic groups\n",
    "    Track false positives, false negatives, and bias metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_by_group = defaultdict(lambda: {\n",
    "            'total': 0,\n",
    "            'true_positives': 0,\n",
    "            'false_positives': 0,\n",
    "            'true_negatives': 0,\n",
    "            'false_negatives': 0,\n",
    "            'quality_scores': [],\n",
    "            'liveness_scores': [],\n",
    "            'match_scores': []\n",
    "        })\n",
    "    \n",
    "    def estimate_skin_tone(self, image: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Estimate skin tone category using simplified ITA° (Individual Typology Angle)\n",
    "        Maps to Fitzpatrick scale categories\n",
    "        \"\"\"\n",
    "        # Convert to LAB color space\n",
    "        if len(image.shape) == 3:\n",
    "            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        else:\n",
    "            # Convert grayscale to BGR first\n",
    "            bgr = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "            lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        # Get L* and b* values from face region\n",
    "        L = np.mean(lab[:, :, 0])\n",
    "        b = np.mean(lab[:, :, 2]) - 128  # Center b* around 0\n",
    "        \n",
    "        # Calculate ITA° (simplified)\n",
    "        if L > 0:\n",
    "            ITA = np.degrees(np.arctan((L - 50) / (b + 1e-6)))\n",
    "        else:\n",
    "            ITA = 0\n",
    "        \n",
    "        # Map ITA° to Fitzpatrick categories\n",
    "        if ITA > 55:\n",
    "            return \"Very Fair\"\n",
    "        elif ITA > 41:\n",
    "            return \"Fair\"\n",
    "        elif ITA > 28:\n",
    "            return \"Medium\"\n",
    "        elif ITA > 10:\n",
    "            return \"Olive\"\n",
    "        elif ITA > -30:\n",
    "            return \"Brown\"\n",
    "        else:\n",
    "            return \"Dark\"\n",
    "    \n",
    "    def log_result(self, image: np.ndarray, ground_truth: str, prediction: str, \n",
    "                   quality_score: float, liveness_score: float, match_score: float = 0,\n",
    "                   demographic: dict = None):\n",
    "        \"\"\"\n",
    "        Log a result for fairness analysis\n",
    "        \n",
    "        Args:\n",
    "            ground_truth: 'unique' or 'duplicate'\n",
    "            prediction: 'UNIQUE', 'DUPLICATE', or 'MANUAL_REVIEW'\n",
    "        \"\"\"\n",
    "        if demographic is None:\n",
    "            demographic = {}\n",
    "        \n",
    "        # Estimate skin tone if not provided\n",
    "        skin_tone = demographic.get('skin_tone', self.estimate_skin_tone(image))\n",
    "        age_group = demographic.get('age_group', '26-35')  # Default\n",
    "        gender = demographic.get('gender', 'Unknown')\n",
    "        \n",
    "        # Log for each demographic dimension\n",
    "        for group_key in [\n",
    "            f\"skin_tone:{skin_tone}\",\n",
    "            f\"age_group:{age_group}\",\n",
    "            f\"gender:{gender}\",\n",
    "            \"overall\"\n",
    "        ]:\n",
    "            stats = self.results_by_group[group_key]\n",
    "            stats['total'] += 1\n",
    "            stats['quality_scores'].append(quality_score)\n",
    "            stats['liveness_scores'].append(liveness_score)\n",
    "            stats['match_scores'].append(match_score)\n",
    "            \n",
    "            # Track confusion matrix\n",
    "            if ground_truth == 'duplicate' and prediction == 'DUPLICATE':\n",
    "                stats['true_positives'] += 1\n",
    "            elif ground_truth == 'unique' and prediction == 'UNIQUE':\n",
    "                stats['true_negatives'] += 1\n",
    "            elif ground_truth == 'unique' and prediction == 'DUPLICATE':\n",
    "                stats['false_positives'] += 1\n",
    "            elif ground_truth == 'duplicate' and prediction == 'UNIQUE':\n",
    "                stats['false_negatives'] += 1\n",
    "    \n",
    "    def calculate_metrics(self, group_key: str) -> dict:\n",
    "        \"\"\"Calculate fairness metrics for a group\"\"\"\n",
    "        stats = self.results_by_group[group_key]\n",
    "        \n",
    "        if stats['total'] == 0:\n",
    "            return {}\n",
    "        \n",
    "        tp = stats['true_positives']\n",
    "        fp = stats['false_positives']\n",
    "        tn = stats['true_negatives']\n",
    "        fn = stats['false_negatives']\n",
    "        \n",
    "        # Calculate rates\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # True Positive Rate (Recall)\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0  # False Negative Rate\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / stats['total'] if stats['total'] > 0 else 0\n",
    "        \n",
    "        f1_score = 2 * precision * tpr / (precision + tpr) if (precision + tpr) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'group': group_key,\n",
    "            'total_samples': stats['total'],\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': tpr,\n",
    "            'f1_score': f1_score,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr,\n",
    "            'avg_quality': np.mean(stats['quality_scores']) if stats['quality_scores'] else 0,\n",
    "            'avg_liveness': np.mean(stats['liveness_scores']) if stats['liveness_scores'] else 0,\n",
    "            'avg_match': np.mean(stats['match_scores']) if stats['match_scores'] else 0\n",
    "        }\n",
    "    \n",
    "    def generate_fairness_report(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate comprehensive fairness report\"\"\"\n",
    "        metrics_list = []\n",
    "        \n",
    "        for group_key in self.results_by_group.keys():\n",
    "            metrics = self.calculate_metrics(group_key)\n",
    "            if metrics:\n",
    "                metrics_list.append(metrics)\n",
    "        \n",
    "        if not metrics_list:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(metrics_list)\n",
    "        return df\n",
    "    \n",
    "    def visualize_fairness(self):\n",
    "        \"\"\"Visualize fairness metrics across demographics\"\"\"\n",
    "        df = self.generate_fairness_report()\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"No data available for fairness analysis\")\n",
    "            return\n",
    "        \n",
    "        # Separate by demographic type\n",
    "        skin_tone_df = df[df['group'].str.contains('skin_tone:')]\n",
    "        age_df = df[df['group'].str.contains('age_group:')]\n",
    "        gender_df = df[df['group'].str.contains('gender:')]\n",
    "        overall_df = df[df['group'] == 'overall']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Plot 1: Accuracy across skin tones\n",
    "        if not skin_tone_df.empty:\n",
    "            skin_tones = [g.split(':')[1] for g in skin_tone_df['group']]\n",
    "            axes[0, 0].bar(skin_tones, skin_tone_df['accuracy'], color='#3498db')\n",
    "            axes[0, 0].set_title('Accuracy by Skin Tone', fontsize=12, fontweight='bold')\n",
    "            axes[0, 0].set_ylabel('Accuracy')\n",
    "            axes[0, 0].set_ylim(0, 1)\n",
    "            axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "            axes[0, 0].axhline(y=0.9, color='#2ecc71', linestyle='--', label='Target', alpha=0.7)\n",
    "            axes[0, 0].legend()\n",
    "        \n",
    "        # Plot 2: FPR vs FNR by skin tone\n",
    "        if not skin_tone_df.empty:\n",
    "            x = np.arange(len(skin_tones))\n",
    "            width = 0.35\n",
    "            axes[0, 1].bar(x - width/2, skin_tone_df['fpr'], width, label='False Positive Rate', color='#e74c3c')\n",
    "            axes[0, 1].bar(x + width/2, skin_tone_df['fnr'], width, label='False Negative Rate', color='#f39c12')\n",
    "            axes[0, 1].set_title('Error Rates by Skin Tone', fontsize=12, fontweight='bold')\n",
    "            axes[0, 1].set_ylabel('Rate')\n",
    "            axes[0, 1].set_xticks(x)\n",
    "            axes[0, 1].set_xticklabels(skin_tones, rotation=45)\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].set_ylim(0, 0.5)\n",
    "        \n",
    "        # Plot 3: Quality and Liveness scores by skin tone\n",
    "        if not skin_tone_df.empty:\n",
    "            x = np.arange(len(skin_tones))\n",
    "            width = 0.35\n",
    "            axes[1, 0].bar(x - width/2, skin_tone_df['avg_quality'], width, label='Quality Score', color='#9b59b6')\n",
    "            axes[1, 0].bar(x + width/2, skin_tone_df['avg_liveness'] * 100, width, label='Liveness Score', color='#1abc9c')\n",
    "            axes[1, 0].set_title('Quality & Liveness by Skin Tone', fontsize=12, fontweight='bold')\n",
    "            axes[1, 0].set_ylabel('Score')\n",
    "            axes[1, 0].set_xticks(x)\n",
    "            axes[1, 0].set_xticklabels(skin_tones, rotation=45)\n",
    "            axes[1, 0].legend()\n",
    "        \n",
    "        # Plot 4: Overall metrics summary\n",
    "        if not overall_df.empty:\n",
    "            overall_metrics = {\n",
    "                'Accuracy': overall_df.iloc[0]['accuracy'],\n",
    "                'Precision': overall_df.iloc[0]['precision'],\n",
    "                'Recall': overall_df.iloc[0]['recall'],\n",
    "                'F1 Score': overall_df.iloc[0]['f1_score']\n",
    "            }\n",
    "            \n",
    "            bars = axes[1, 1].barh(list(overall_metrics.keys()), list(overall_metrics.values()), \n",
    "                                   color=['#2ecc71', '#3498db', '#9b59b6', '#e74c3c'])\n",
    "            axes[1, 1].set_xlim(0, 1)\n",
    "            axes[1, 1].set_title('Overall System Performance', fontsize=12, fontweight='bold')\n",
    "            axes[1, 1].set_xlabel('Score')\n",
    "            \n",
    "            for i, (k, v) in enumerate(overall_metrics.items()):\n",
    "                axes[1, 1].text(v + 0.02, i, f'{v:.2%}', va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Fairness Analysis Dashboard', fontsize=16, fontweight='bold', y=1.00)\n",
    "        plt.show()\n",
    "\n",
    "# Initialize fairness analyzer\n",
    "fairness_analyzer = FairnessAnalyzer()\n",
    "\n",
    "print(\"✓ Fairness Analyzer initialized\")\n",
    "print(\"  Demographic dimensions:\")\n",
    "print(\"    • Skin tone (6 categories based on Fitzpatrick scale)\")\n",
    "print(\"    • Age groups (5 bins)\")\n",
    "print(\"    • Gender\")\n",
    "print(\"  Metrics tracked:\")\n",
    "print(\"    • Accuracy, Precision, Recall, F1-Score\")\n",
    "print(\"    • False Positive Rate (FPR)\")\n",
    "print(\"    • False Negative Rate (FNR)\")\n",
    "print(\"    • Average quality and liveness scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5a392",
   "metadata": {},
   "source": [
    "## 15. Scalability Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_scalability():\n",
    "    \"\"\"Test system performance at different scales\"\"\"\n",
    "    scales = [100, 500, 1000, 5000]\n",
    "    results = []\n",
    "    \n",
    "    print(\"Scalability Benchmark\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for n in scales:\n",
    "        print(f\"\\nTesting with {n:,} templates...\")\n",
    "        \n",
    "        temp_index = LSHFaceHashIndex(\n",
    "            dim=config.CANCELABLE_DIM,\n",
    "            num_tables=config.LSH_NUM_TABLES,\n",
    "            num_bits=config.LSH_NUM_BITS\n",
    "        )\n",
    "        \n",
    "        # Insert templates\n",
    "        insert_times = []\n",
    "        for i in range(n):\n",
    "            template = np.random.randn(config.CANCELABLE_DIM).astype(np.float32)\n",
    "            template = template / (np.linalg.norm(template) + 1e-8)\n",
    "            \n",
    "            start = time.time()\n",
    "            temp_index.insert(f\"app_{i}\", template, {})\n",
    "            insert_times.append(time.time() - start)\n",
    "        \n",
    "        # Query performance\n",
    "        query_times = []\n",
    "        for _ in range(20):\n",
    "            query_template = np.random.randn(config.CANCELABLE_DIM).astype(np.float32)\n",
    "            query_template = query_template / (np.linalg.norm(query_template) + 1e-8)\n",
    "            \n",
    "            start = time.time()\n",
    "            temp_index.query(query_template)\n",
    "            query_times.append(time.time() - start)\n",
    "        \n",
    "        result = {\n",
    "            'size': n,\n",
    "            'insert_ms': np.mean(insert_times) * 1000,\n",
    "            'query_ms': np.mean(query_times) * 1000,\n",
    "            'throughput': 1.0 / np.mean(query_times)\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        print(f\"  Query Time: {result['query_ms']:.2f} ms\")\n",
    "        print(f\"  Throughput: {result['throughput']:.0f} queries/sec\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run benchmark\n",
    "scalability_df = benchmark_scalability()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(scalability_df['size'], scalability_df['query_ms'], marker='o', linewidth=2)\n",
    "axes[0].set_xlabel('Database Size')\n",
    "axes[0].set_ylabel('Query Time (ms)')\n",
    "axes[0].set_title('Query Performance')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(scalability_df['size'], scalability_df['throughput'], marker='s', linewidth=2)\n",
    "axes[1].set_xlabel('Database Size')\n",
    "axes[1].set_ylabel('Queries/Second')\n",
    "axes[1].set_title('Throughput')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProjection for India scale:\")\n",
    "print(f\"  5M applications: ~{scalability_df['query_ms'].iloc[-1] * 2:.1f} ms per query\")\n",
    "print(f\"  Daily capacity: ~{scalability_df['throughput'].iloc[-1] * 86400 / 16:.0f} apps/day (16-core)\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a37025",
   "metadata": {},
   "source": [
    "## 16. Summary\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "**Privacy & Security**\n",
    "- Cancelable biometric templates (revocable, 50% smaller)\n",
    "- LSH-based encrypted search buckets\n",
    "- Complete audit trail for DPDP compliance\n",
    "\n",
    "**Performance**\n",
    "- Two-stage pipeline: 50,000x fewer comparisons\n",
    "- Sub-linear search complexity O(log N)\n",
    "- Tested on real LFW dataset with {accuracy:.1%} accuracy\n",
    "\n",
    "**Fairness & Trust**\n",
    "- Bias monitoring across demographics\n",
    "- Explainability dashboard for human review\n",
    "- Risk-based decisions with manual review option\n",
    "\n",
    "### Next Steps for Production\n",
    "1. Replace with production models (InsightFace/ArcFace)\n",
    "2. Deploy with GPU acceleration and ONNX optimization\n",
    "3. Add 3D liveness and morph attack detection\n",
    "4. Expand fairness testing with Indian demographics\n",
    "\n",
    "---\n",
    "\n",
    "**Developed for IndiaAI Face Authentication Challenge**  \n",
    "**October 2025**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
